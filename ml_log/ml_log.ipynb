{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = '/Users/kkryuu/Desktop/G-able/ci-test/ml_log/log_win_2023-08-30_P29140_20230831_162752.log'\n",
    "\n",
    "logerror = []\n",
    "logfailed = []\n",
    "err_msg = []\n",
    "err = []\n",
    "\n",
    "# Read the log file line by line\n",
    "with open(log_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        if \"error:\" in line.strip().lower() or \"error :\" in line.strip().lower():\n",
    "            logerror.append({'Logerror': line})\n",
    "            if \n",
    "\n",
    "        if \"fail\" in line.strip().lower() and \"0\" not in line.strip().lower() :\n",
    "            logfailed.append({'Logfail': line})\n",
    "        if \"err_msg:\" in line.strip().lower():\n",
    "            err_msg.append({'err_msg': line})\n",
    "        if \"err_msg: NULL\" not in err_msg:\n",
    "            err.append({'err_msg': line})\n",
    "# queryId\n",
    "# Create a DataFrame from the list of log entries\n",
    "logerror_df = pd.DataFrame(logerror)\n",
    "logfailed_df = pd.DataFrame(logfailed)\n",
    "err_msg_df = pd.DataFrame(err_msg)\n",
    "err_df = pd.DataFrame(err)\n",
    "\n",
    "# Create a DataFrame with the log entries\n",
    "# logerror = pd.DataFrame(log_entries, columns=['LogEntry'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Logerror\n",
      "0  ERROR : FAILED: Execution Error, return code 1...\n",
      "1  Error: Error while processing statement: FAILE...\n",
      "2  ERROR : FAILED: Execution Error, return code 1...\n",
      "3  Error: Error while processing statement: FAILE...\n",
      "4  ERROR : FAILED: Execution Error, return code 1...\n",
      "5  Error: Error while processing statement: FAILE...\n",
      "6  ERROR : FAILED: Execution Error, return code 1...\n",
      "7  Error: Error while processing statement: FAILE...\n",
      "8  Info Error:::: No Custom Audit and SRC is not ...\n",
      "9  Info Error:::: Failed to load the data for aud...\n"
     ]
    }
   ],
   "source": [
    "print(logerror_df)\n",
    "logerror_df['Logerror'] = logerror_df['Logerror'].str.replace('\\n', '')\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "logerror_df.to_csv('/Users/kkryuu/Desktop/G-able/ci-test/ml_log/logerror_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logfail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALLOW_FAIL:N IS_BYPASS:N\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFO: Failed to create one or more destination...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\u001b[2K\u001b[36;1m        VERTICES      MODE        S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\u001b[2K\u001b[36;1m        VERTICES      MODE        S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\u001b[2K\u001b[36;1m        VERTICES      MODE        S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>\u001b[2K\u001b[36;1m        VERTICES      MODE        S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>\u001b[2K\u001b[36;1m        VERTICES      MODE        S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>\u001b[2K\u001b[36;1m        VERTICES      MODE        S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>\u001b[2K\u001b[36;1m        VERTICES      MODE        S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>\u001b[2K\u001b[36;1m        VERTICES      MODE        S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2051 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Logfail\n",
       "0                            ALLOW_FAIL:N IS_BYPASS:N\\n\n",
       "1     INFO: Failed to create one or more destination...\n",
       "2     \u001b[2K\u001b[36;1m        VERTICES      MODE        S...\n",
       "3     \u001b[2K\u001b[36;1m        VERTICES      MODE        S...\n",
       "4     \u001b[2K\u001b[36;1m        VERTICES      MODE        S...\n",
       "...                                                 ...\n",
       "2046  \u001b[2K\u001b[36;1m        VERTICES      MODE        S...\n",
       "2047  \u001b[2K\u001b[36;1m        VERTICES      MODE        S...\n",
       "2048  \u001b[2K\u001b[36;1m        VERTICES      MODE        S...\n",
       "2049  \u001b[2K\u001b[36;1m        VERTICES      MODE        S...\n",
       "2050  \u001b[2K\u001b[36;1m        VERTICES      MODE        S...\n",
       "\n",
       "[2051 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logfailed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             err_msg\n",
      "0    err_msg: NULL\\n\n",
      "1    err_msg: NULL\\n\n",
      "2    err_msg: NULL\\n\n",
      "3    err_msg: NULL\\n\n",
      "4    err_msg: NULL\\n\n",
      "..               ...\n",
      "939  err_msg: NULL\\n\n",
      "940  err_msg: NULL\\n\n",
      "941  err_msg: NULL\\n\n",
      "942  err_msg: NULL\\n\n",
      "943  err_msg: NULL\\n\n",
      "\n",
      "[944 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(err_msg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err_msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Info:::: Job di_wrapper_to_hdfs.sh executer Us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Info:::: Mode : DEFAULT\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Info:::: Job input run date is RUN_DATE : 2023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Info:::: Job di_wrapper_to_hdfs.sh running dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Info:::: Job di_wrapper_to_hdfs.sh is running ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107354</th>\n",
       "      <td>Info:::: Resource Manager Queue set to batch_j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107355</th>\n",
       "      <td>BASE_DIR=/datagrid/dlprod/raw/etl\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107356</th>\n",
       "      <td>2023-10-05 08:10:31Info:::: start audit\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107357</th>\n",
       "      <td>2023-10-05 08:10:34Info:::: end audit\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107358</th>\n",
       "      <td>LOG_PATH: /datagrid/dlprod_log/202310/raw/etl/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107359 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  err_msg\n",
       "0       Info:::: Job di_wrapper_to_hdfs.sh executer Us...\n",
       "1                               Info:::: Mode : DEFAULT\\n\n",
       "2       Info:::: Job input run date is RUN_DATE : 2023...\n",
       "3       Info:::: Job di_wrapper_to_hdfs.sh running dat...\n",
       "4       Info:::: Job di_wrapper_to_hdfs.sh is running ...\n",
       "...                                                   ...\n",
       "107354  Info:::: Resource Manager Queue set to batch_j...\n",
       "107355                BASE_DIR=/datagrid/dlprod/raw/etl\\n\n",
       "107356          2023-10-05 08:10:31Info:::: start audit\\n\n",
       "107357            2023-10-05 08:10:34Info:::: end audit\\n\n",
       "107358  LOG_PATH: /datagrid/dlprod_log/202310/raw/etl/...\n",
       "\n",
       "[107359 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "log_file_path = '/Users/kkryuu/Desktop/G-able/ci-test/los_20231109.csv'\n",
    "\n",
    "filename_df = pd.read_csv(log_file_path)\n",
    "# Save each entry to a separate CSV file\n",
    "output_directory = '/Users/kkryuu/Desktop/G-able/ci-test/ml_log/los_20231109'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "for index, row in filename_df.iterrows():\n",
    "    csv_filename = os.path.join(output_directory, f\"{row['name']}\")\n",
    "    row.to_csv(csv_filename, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     CARDXLIS_DXCARDX_LIS_ACCOUNTINFO_D20231108_1.C...\n",
       "1      CARDXLIS_DXCARDX_LIS_ACCOUNTINFO_D20231108_1.CTL\n",
       "2     CARDXLIS_DXCARDX_LIS_ACCOUNTINFO_D20231108_2.C...\n",
       "3      CARDXLIS_DXCARDX_LIS_ACCOUNTINFO_D20231108_2.CTL\n",
       "4     CARDXLIS_DXCARDX_LIS_ACCOUNTNEGOTIATIONSTATUS_...\n",
       "                            ...                        \n",
       "59       CARDXLIS_DXCARDX_MDT_PRODUCTTYPE_D20231108.CTL\n",
       "60       CARDXLIS_DXCARDX_MDT_PRODUCT_D20231108.CSV.PGP\n",
       "61           CARDXLIS_DXCARDX_MDT_PRODUCT_D20231108.CTL\n",
       "62    CARDXLIS_DXCARDX_MDT_TRANSACTIONCODE_D20231108...\n",
       "63    CARDXLIS_DXCARDX_MDT_TRANSACTIONCODE_D20231108...\n",
       "Name: name, Length: 64, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score, classification_report\n\u001b[1;32m      7\u001b[0m \u001b[39m# Assuming you have a DataFrame named 'log_df' with columns 'LogData' and 'ErrorType'\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[39m# Data Preparation\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# Assuming 'ErrorType' contains 'Error' for error entries and 'Info' for non-error entries\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m log_df[\u001b[39m'\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m log_df[\u001b[39m'\u001b[39m\u001b[39mErrorType\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mError\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m x \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39m# Train-test split\u001b[39;00m\n\u001b[1;32m     14\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(log_df[\u001b[39m'\u001b[39m\u001b[39mLogData\u001b[39m\u001b[39m'\u001b[39m], log_df[\u001b[39m'\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m'\u001b[39m], test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming you have a DataFrame named 'log_df' with columns 'LogData' and 'ErrorType'\n",
    "\n",
    "# Data Preparation\n",
    "# Assuming 'ErrorType' contains 'Error' for error entries and 'Info' for non-error entries\n",
    "log_df['Label'] = log_df['ErrorType'].apply(lambda x: 1 if 'Error' in x else 0)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(log_df['LogData'], log_df['Label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Text Preprocessing and Feature Extraction\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Model Training\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test_vec)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/e3/52/fd60b0b022af41fbf3463587ddc719288f0f2d4e46603ab3184996cd5f04/scikit_learn-1.3.2-cp38-cp38-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/kkryuu/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from scikit-learn) (1.24.4)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-macosx_10_9_x86_64.whl (35.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.2-cp38-cp38-macosx_10_9_x86_64.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 scipy-1.10.1 threadpoolctl-3.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
